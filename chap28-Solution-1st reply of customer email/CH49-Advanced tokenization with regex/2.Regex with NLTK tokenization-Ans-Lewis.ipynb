{"cells":[{"cell_type":"markdown","metadata":{"id":"2panrE6z43-u"},"source":["# 練習\n","## Regex with NLTK tokenization\n","Twitter is a frequently used source for NLP text and tasks. In this exercise, you'll build a more complex tokenizer for tweets with hashtags and mentions using nltk and regex. The nltk.tokenize.TweetTokenizer class gives you some extra methods and attributes for parsing tweets.\n","\n","Here, you're given some example tweets to parse using both TweetTokenizer and regexp_tokenize from the nltk.tokenize module. These example tweets have been pre-loaded into the variable tweets. Feel free to explore it in the IPython Shell!\n","\n","Unlike the syntax for the regex library, with nltk_tokenize() you pass the pattern as the second argument."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"xg3_Mnsg43-5","executionInfo":{"status":"ok","timestamp":1669515697280,"user_tz":-480,"elapsed":33,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}}},"outputs":[],"source":["# 準備事項\n","# From nltk.tokenize, import regexp_tokenize and TweetTokenizer.\n","tweets = ['This is the best #nlp exercise ive found online! #python', \n","          '#NLP is super fun! <3 #learning', \n","          'Thanks @datacamp :) #nlp #python']"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gGk8Eor143-9","executionInfo":{"status":"ok","timestamp":1669515763235,"user_tz":-480,"elapsed":2197,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}}},"outputs":[],"source":["# Import the necessary modules\n","from nltk.tokenize import regexp_tokenize\n","from nltk.tokenize import TweetTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vuWb7DYH43-_"},"outputs":[],"source":["# 準備事項\n","# A regex pattern to define hashtags called pattern1 has been defined for you. Call regexp_tokenize() with this hashtag pattern on the first tweet in tweets and assign the result to hashtags.\n","# Print hashtags (this has already been done for you)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Ckj5Enn43_A"},"outputs":[],"source":["regexp_tokenize?"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NyWQ1it43_C","executionInfo":{"status":"ok","timestamp":1669515777237,"user_tz":-480,"elapsed":271,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}},"outputId":"b9993176-c4ac-40af-80bd-e48862ff4f2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['#nlp', '#python']\n"]}],"source":["# Import the necessary modules\n","from nltk.tokenize import regexp_tokenize\n","from nltk.tokenize import TweetTokenizer\n","# Define a regex pattern to find hashtags: pattern1\n","pattern1 = r\"#\\w+\"\n","# Use the pattern on the first tweet in the tweets list\n","hashtags = regexp_tokenize(tweets[0], pattern1)\n","print(hashtags)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGPVZCBL43_H"},"outputs":[],"source":["# 預計結果\n","# ['#nlp', '#python']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbSaum0O43_J"},"outputs":[],"source":["# 準備事項\n","# Write a new pattern called pattern2 to match mentions and hashtags. A mention is something like @DataCamp.\n","\n","# Then, call regexp_tokenize() with your new hashtag pattern on the last tweet in tweets and assign the result to mentions_hashtags.\n","\n","# You can access the last element of a list using -1 as the index, for example, tweets[-1].\n","# Print mentions_hashtags (this has been done for you)."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"ZhV0XJmt43_L","executionInfo":{"status":"ok","timestamp":1669515794557,"user_tz":-480,"elapsed":435,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}},"outputId":"9b734573-3a87-4524-b185-34548d7bf27e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Thanks @datacamp :) #nlp #python'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["tweets[-1]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R59UkvUd43_M","executionInfo":{"status":"ok","timestamp":1669515804657,"user_tz":-480,"elapsed":273,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}},"outputId":"83a03d11-0bb2-4865-c5e0-0f0e9f1c42c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["['@datacamp', '#nlp', '#python']\n"]}],"source":["# Import the necessary modules\n","from nltk.tokenize import regexp_tokenize\n","from nltk.tokenize import TweetTokenizer\n","# Write a pattern that matches both mentions (@) and hashtags\n","pattern2 = r\"([@|#]\\w+)\"\n","# Use the pattern on the last tweet in the tweets list\n","mentions_hashtags = regexp_tokenize(tweets[-1], pattern2)\n","print(mentions_hashtags)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uwh6UKxw43_O"},"outputs":[],"source":["# 預期結果\n","#['@datacamp', '#nlp', '#python']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IJ0rVALK43_O"},"outputs":[],"source":["# 準備事項\n","# Create an instance of TweetTokenizer called tknzr and use it inside a list comprehension to tokenize each tweet into a new list called all_tokens.\n","# To do this, use the .tokenize() method of tknzr, with t as your iterator variable.\n","# Print all_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJvnn0It43_P"},"outputs":[],"source":["TweetTokenizer?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWuXO8Ej43_Q","outputId":"6628daf6-35d2-4aa4-f329-378971cbe96d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['This', 'is', 'the', 'best', '#nlp', 'exercise', 'ive', 'found', 'online', '!', '#python'], ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'], ['Thanks', '@datacamp', ':)', '#nlp', '#python']]\n"]}],"source":["# Import the necessary modules\n","from nltk.tokenize import regexp_tokenize\n","from nltk.tokenize import TweetTokenizer\n","# Use the TweetTokenizer to tokenize all tweets into one list\n","tknzr = TweetTokenizer()\n","all_tokens = [tknzr.tokenize(t) for t in tweets]\n","print(all_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RF5oRYaf43_R"},"outputs":[],"source":["# 預期結果\n","# [['This', 'is', 'the', 'best', '#nlp', 'exercise', 'ive', 'found', 'online', '!', '#python'], ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'], ['Thanks', '@datacamp', ':)', '#nlp', '#python']]"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}