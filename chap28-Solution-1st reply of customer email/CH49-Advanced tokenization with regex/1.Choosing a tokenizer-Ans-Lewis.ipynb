{"cells":[{"cell_type":"markdown","metadata":{"id":"UDRSSCso3q8v"},"source":["# 練習\n","## Choosing a tokenizer\n","Given the following string, which of the below patterns is the best tokenizer? If possible, you want to retain sentence punctuation as separate tokens, but have '#1' remain a single token.\n","\n","#### my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"\n","\n","The string is available in your workspace as my_string, and the patterns have been pre-loaded as pattern1, pattern2, pattern3, and pattern4, respectively.\n","\n","Additionally, regexp_tokenize has been imported from nltk.tokenize. You can use regexp_tokenize(string, pattern) with my_string and one of the patterns as arguments to experiment for yourself and see which is the best tokenizer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T6RAAiPS3q86"},"outputs":[],"source":["# Possible Answers\n","# ( ) r\"(\\w+|\\?|!)\"\n","# ( ) r\"(\\w+|#\\d|\\?|!)\"\n","# ( ) r\"(#\\d\\w+\\?!)\"\n","# ( ) r\"\\s+\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSXiOR_G3q89","executionInfo":{"status":"ok","timestamp":1669515645677,"user_tz":-480,"elapsed":293,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}},"outputId":"9975814f-7012-43ee-aa2f-609e8cd90944"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['SOLDIER',\n"," '#1:',\n"," 'Found',\n"," 'them?',\n"," 'In',\n"," 'Mercea?',\n"," 'The',\n"," 'coconut',\n"," 's',\n"," 'tropical!']"]},"metadata":{},"execution_count":5}],"source":["import re\n","my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"\n","re.split(r\"[\\s ']+\" , my_string )"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WO0d6JLr3q9A","executionInfo":{"status":"ok","timestamp":1669515614083,"user_tz":-480,"elapsed":296,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}},"outputId":"cfcf12c7-3ca7-42f9-eed7-68436ccd2337"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['SOLDIER',\n"," '#1',\n"," 'Found',\n"," 'them',\n"," '?',\n"," 'In',\n"," 'Mercea',\n"," '?',\n"," 'The',\n"," 'coconut',\n"," 's',\n"," 'tropical',\n"," '!']"]},"metadata":{},"execution_count":4}],"source":["from nltk.tokenize import regexp_tokenize\n","regexp_tokenize(my_string, pattern=r\"(\\w+|#\\d|\\?|!)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tkrc4xaK3q9D"},"outputs":[],"source":["# 預計答案\n","# ['SOLDIER',\n","#  '#1',\n","#  'Found',\n","#  'them',\n","#  '?',\n","#  'In',\n","#  'Mercea',\n","#  '?',\n","#  'The',\n","#  'coconut',\n","#  's',\n","#  'tropical',\n","#  '!']"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}