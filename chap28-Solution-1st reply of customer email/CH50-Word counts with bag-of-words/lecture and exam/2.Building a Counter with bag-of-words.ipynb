{"cells":[{"cell_type":"markdown","metadata":{"id":"n_YMpDWHThvI"},"source":["# 練習\n","## Building a Counter with bag-of-words\n","In this exercise, you'll build your first (in this course) bag-of-words counter using a Wikipedia article, which has been pre-loaded as article. Try doing the bag-of-words without looking at the full article text, and guessing what the topic is! If you'd like to peek at the title at the end, we've included it as article_title. Note that this article text has had very little preprocessing from the raw Wikipedia database entry.\n","\n","word_tokenize has been imported for you."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"iwUidQTLThvQ"},"outputs":[],"source":["# 準備事項\n","\n","# Import Counter from collections.\n","# Use word_tokenize() to split the article into tokens.\n","# Use a list comprehension with t as the iterator variable to convert all the tokens into lowercase. The .lower() method converts text into lowercase.\n","# Create a bag-of-words counter called bow_simple by using Counter() with lower_tokens as the argument.\n","# Use the .most_common() method of bow_simple to print the 10 most common tokens.\n","\n","\n","article_title = 'Debugging'\n","with open('article.txt') as f:\n","    article = f.read() "]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbX3FI0HT6lA","executionInfo":{"status":"ok","timestamp":1669522858259,"user_tz":-480,"elapsed":787,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}},"outputId":"751960f2-8117-4253-fbdc-9009b19c936e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4DQU5wlThvX","executionInfo":{"status":"ok","timestamp":1669522887847,"user_tz":-480,"elapsed":12,"user":{"displayName":"Lewis Yang","userId":"11249979140389061982"}},"outputId":"63f8a80d-aade-47ec-941a-35c61ee44532"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(',', 151), ('the', 150), ('.', 89), ('of', 81), (\"''\", 69), ('to', 63), ('a', 60), ('``', 47), ('in', 44), ('and', 41), ('(', 40), (')', 40)]\n"]}],"source":["# Import Counter\n","from collections import Counter\n","from nltk.tokenize import word_tokenize\n","# Tokenize the article: tokens\n","tokens = word_tokenize(article)\n","\n","# Convert the tokens into lowercase: lower_tokens\n","lower_tokens = [t.lower() for t in tokens]\n","\n","# Create a Counter with the lowercase tokens: bow_simple\n","bow_simple = Counter(lower_tokens)\n","\n","# Print the 10 most common tokens\n","print(bow_simple.most_common(12))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jRQo0Q1TThvZ"},"outputs":[],"source":["# 預期結果\n","# <script.py> output:\n","#     [(',', 151), ('the', 150), ('.', 89), ('of', 81), (\"''\", 68), ('to', 63), ('a', 60), ('in', 44), ('and', 41), ('debugging', 40)]"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}