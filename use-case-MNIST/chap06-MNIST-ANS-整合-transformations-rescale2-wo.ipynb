{"cells":[{"cell_type":"code","execution_count":null,"id":"e96ce2fe","metadata":{"id":"e96ce2fe"},"outputs":[],"source":["# 請將所有手寫辨識 28 * 28 --> 56 * 56\n","# with    anti-aliasing\n","# without anti-aliasing"]},{"cell_type":"code","execution_count":null,"id":"worth-departure","metadata":{"id":"worth-departure","outputId":"ebec183c-4e3b-4127-dad3-2c39ac22040c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_4 (Dense)              (None, 128)               1605760   \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,607,050\n","Trainable params: 1,607,050\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# 導入函式庫\n","import numpy as np  \n","import keras\n","# from keras.models import Sequential\n","from keras.datasets import mnist\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding  \n","from matplotlib import pyplot as plt\n","import os\n","from datetime import datetime\n","\n","start=datetime.now()\n","\n","# 載入 MNIST 資料庫的訓練資料，並自動分為『訓練組』及『測試組』\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# 建立簡單的線性執行的模型\n","model = keras.models.Sequential()\n","# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n","model.add(Dense(units=128, input_dim=112*112, kernel_initializer='normal', activation='relu')) \n","# Add output layer\n","model.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n","\n","# 編譯: 選擇損失函數、優化方法及成效衡量方式\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"id":"62d344f5","metadata":{"id":"62d344f5","outputId":"17b58b28-7f95-4e32-a223-c260debecaac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Preprocessed by skimage.rescale\n","Wall time: 4min 39s\n"]}],"source":["%%time\n","# 可以試試這樣做 僅是部分資料\n","from tqdm import tqdm # 跑出步近圖\n","import numpy as np\n","from skimage.filters import gaussian\n","from skimage.filters import sobel\n","from skimage import exposure\n","from skimage.transform import rescale\n","\n","downscale = (4)\n","X_train_skimage = np.array([rescale(x, downscale, anti_aliasing=False, multichannel=False) for x in X_train[:]]) # <--核心價值 change me\n","X_test_skimage = np.array([rescale(x, downscale, anti_aliasing=False, multichannel=False) for x in X_test[:]])  # <--核心價值 change me\n","print('Preprocessed by skimage.rescale')"]},{"cell_type":"code","execution_count":null,"id":"b33d14de","metadata":{"id":"b33d14de","outputId":"044b73ae-8d4f-4d48-8532-f1d388ac52b4"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# 劃出一 原來圖片\n","plt.figure(figsize=(2,2))\n","plt.imshow(X_train[0], cmap='gray')\n","plt.axis('on')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"bbdd8494","metadata":{"id":"bbdd8494","outputId":"a88b48ac-77e3-4fa2-d559-d77f56fb7015"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Data range after preprocessed 0.0 0.9921568627450981\n"]}],"source":["# 劃出一圖片\n","plt.figure(figsize=(2,2))\n","plt.imshow(X_train_skimage[0], cmap='gray')\n","plt.axis('on')\n","plt.show()\n","print('Data range after preprocessed', X_train_skimage[0].min(), X_train_skimage[0].max())"]},{"cell_type":"code","execution_count":null,"id":"8731dfa7","metadata":{"scrolled":false,"id":"8731dfa7","outputId":"fe6e69dc-d6b7-48d8-eeec-a3f2553075ba"},"outputs":[{"ename":"InternalError","evalue":"Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[1;32mC:\\Users\\LEWIS_~1\\AppData\\Local\\Temp/ipykernel_12680/3887432765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# 進行訓練, 訓練過程會存在 train_history 變數中\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m train_history = model.fit(x=x_Train_norm, y=y_TrainOneHot, \n\u001b[0m\u001b[0;32m     17\u001b[0m                           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                           batch_size=800, verbose=2)  \n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1141\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1144\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1398\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1400\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1155\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1156\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m                **kwargs):\n\u001b[0;32m    246\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    249\u001b[0m         sample_weights, sample_weight_modes)\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m-> 1430\u001b[1;33m   return convert_to_tensor_v2(\n\u001b[0m\u001b[0;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   \u001b[1;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m   return convert_to_tensor(\n\u001b[0m\u001b[0;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."]}],"source":["# 將 training 的 label 進行 one-hot encoding，例如數字 7 經過 One-hot encoding 轉換後是 0000001000，即第7個值為 1\n","y_TrainOneHot = np_utils.to_categorical(y_train) \n","y_TestOneHot = np_utils.to_categorical(y_test) \n","\n","# 將 training 的 input 資料轉為2維\n","X_train = X_train_skimage #<--------------preprocessed by skimage\n","X_test  = X_test_skimage  #<--------------preprocessed by skimage\n","\n","X_train_2D = X_train.reshape(60000, 112*112).astype('float32')  #< -----\n","X_test_2D = X_test.reshape(10000, 112*112).astype('float32')    #< -----\n","\n","x_Train_norm = X_train_2D # /255.0  #<-------取消\n","x_Test_norm = X_test_2D   # /255.0  #<-------取消\n","\n","# 進行訓練, 訓練過程會存在 train_history 變數中\n","train_history = model.fit(x=x_Train_norm, y=y_TrainOneHot, \n","                          validation_split=0.2, epochs=10, \n","                          batch_size=800, verbose=2)  "]},{"cell_type":"code","execution_count":null,"id":"attended-arrow","metadata":{"id":"attended-arrow"},"outputs":[],"source":["# 顯示訓練成果(分數)\n","scores = model.evaluate(x_Test_norm, y_TestOneHot)  \n","print()  \n","print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))  \n"]},{"cell_type":"code","execution_count":null,"id":"9757dc3d","metadata":{"id":"9757dc3d"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"chap06-MNIST-ANS-整合-transformations-rescale2-wo.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}